{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MyfMmMnPJjvn"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zjcGOJhcJjvp"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jR0Pl2XjJjvq"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU8_k_av8sgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "7ccbfbf8-b05d-4f0f-f41c-2e5b5de23793"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qr75v_UYJjvs",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hTI42-0qJjvw"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g2sf67VoJjvx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d352a874-3924-4e36-a0a0-808bbb99bfb4"
      },
      "source": [
        "x_train.shape #number of samples in train"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bphn_Ggk8sg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e84501e-4923-4a7c-ff55-17cc34fd461e"
      },
      "source": [
        "x_test.shape #number of samples in test"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WytT2eRnJjv4"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XycQGBSGJjv5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbe89209-16ba-418d-b280-a5bf1a4021a5"
      },
      "source": [
        "x_train[:0,:,:].shape  #shape of the image is 28*28"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5jtdZ7RqJjv8"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sAD3q5I6Jjv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a692b58b-9fa3-400a-e281-f1ecca415eb7"
      },
      "source": [
        "import numpy as np\n",
        "np.unique(y_train).shape  #to find the number of classes in y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mgHSCXy3JjwA",
        "colab": {}
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uEcJzyMCXZa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "dd474bc9-9900-4528-a60d-8822c0606b01"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xO5BRBzBJjwD"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3fUQpMHxJjwE",
        "colab": {}
      },
      "source": [
        "x_train=x_train/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Okwo_SB5JjwI",
        "colab": {}
      },
      "source": [
        "x_test=x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "da5-DwgrJjwM"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LPGVQ-JJJjwN",
        "colab": {}
      },
      "source": [
        "x_train=x_train.reshape(x_train.shape[0],28,28,1).astype('float32')    # The digit 1 signifies the images are in grayscale\n",
        "x_test=x_test.reshape(x_test.shape[0],28,28,1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OFRRTJq8JjwQ"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dWTZYnKSJjwR",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C18AoS7eJjwU"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DORCLgSwJjwV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6f8d9118-28dc-4846-e714-5686fb51381e"
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.LayerNormalization())\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH97d9ij8shP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "b398d08f-ff78-4779-fe7c-6f423c40e328"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]\n",
        "model.fit(x_train,y_train ,batch_size=32,callbacks=callback_list,epochs=10,validation_data=(x_test,y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 16s 269us/sample - loss: 0.3732 - acc: 0.8710 - val_loss: 0.3244 - val_acc: 0.8793\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 15s 245us/sample - loss: 0.2176 - acc: 0.9179 - val_loss: 0.2541 - val_acc: 0.9108\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 15s 243us/sample - loss: 0.1541 - acc: 0.9426 - val_loss: 0.2834 - val_acc: 0.9085\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 15s 243us/sample - loss: 0.1069 - acc: 0.9605 - val_loss: 0.3159 - val_acc: 0.9094\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 15s 242us/sample - loss: 0.0759 - acc: 0.9720 - val_loss: 0.4318 - val_acc: 0.9008\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 15s 244us/sample - loss: 0.0573 - acc: 0.9796 - val_loss: 0.4031 - val_acc: 0.9069\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 15s 245us/sample - loss: 0.0434 - acc: 0.9840 - val_loss: 0.4652 - val_acc: 0.9064\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb3ce4dc320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ju69vKdIJjwX"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L2hAP94vJjwY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "d570775f-9e8e-4076-c51a-c12cf37522ba"
      },
      "source": [
        "model1= tf.keras.Sequential()\n",
        "model1.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(28,28,1)))\n",
        "model1.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model1.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides =(2,2), padding='valid'))\n",
        "model1.add(tf.keras.layers.Dropout(0.25))\n",
        "model1.add(tf.keras.layers.LayerNormalization())\n",
        "model1.add(tf.keras.layers.Flatten())\n",
        "model1.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model1.fit(x_train,y_train ,batch_size=32,callbacks=callback_list,epochs=10,validation_data=(x_test,y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 11s 177us/sample - loss: 0.3721 - acc: 0.8636 - val_loss: 0.2739 - val_acc: 0.8993\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 169us/sample - loss: 0.2450 - acc: 0.9090 - val_loss: 0.2562 - val_acc: 0.9067\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.2027 - acc: 0.9239 - val_loss: 0.2369 - val_acc: 0.9185\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 10s 169us/sample - loss: 0.1722 - acc: 0.9353 - val_loss: 0.2447 - val_acc: 0.9183\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 171us/sample - loss: 0.1505 - acc: 0.9430 - val_loss: 0.2491 - val_acc: 0.9218\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 167us/sample - loss: 0.1303 - acc: 0.9510 - val_loss: 0.2561 - val_acc: 0.9216\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 171us/sample - loss: 0.1106 - acc: 0.9578 - val_loss: 0.2745 - val_acc: 0.9213\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 169us/sample - loss: 0.1026 - acc: 0.9611 - val_loss: 0.2666 - val_acc: 0.9264\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.0908 - acc: 0.9656 - val_loss: 0.2839 - val_acc: 0.9246\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0825 - acc: 0.9684 - val_loss: 0.2938 - val_acc: 0.9245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb3c0084780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lGTA3bfEJjwa"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F6gX8n5SJjwb"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cbz4uHBuJjwc",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K19FH0OREIeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(rotation_range=30,height_shift_range=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pl-8dOo7Jjwf"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DpI1_McYJjwg",
        "outputId": "70cb8875-be7a-4bfd-9fef-5be12fe94758",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dmPl5yE8Jjwm"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "44ZnDdJYJjwn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "078e04a6-a659-449a-f4e8-2ef830735ede"
      },
      "source": [
        "model1.fit_generator(datagen.flow(x_train,y_train ,batch_size=32),steps_per_epoch = len(x_train) // 32,epochs=10,validation_data=(x_test,y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.8193 - acc: 0.7004Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 106us/sample - loss: 0.3534 - acc: 0.8638\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.8185 - acc: 0.7007 - val_loss: 0.3904 - val_acc: 0.8638\n",
            "Epoch 2/10\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.5960 - acc: 0.7796Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 104us/sample - loss: 0.3204 - acc: 0.8526\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.5959 - acc: 0.7797 - val_loss: 0.4035 - val_acc: 0.8526\n",
            "Epoch 3/10\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.5435 - acc: 0.7988Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 107us/sample - loss: 0.3093 - acc: 0.8642\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.5435 - acc: 0.7988 - val_loss: 0.3905 - val_acc: 0.8642\n",
            "Epoch 4/10\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.8104Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 108us/sample - loss: 0.3246 - acc: 0.8651\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.5099 - acc: 0.8104 - val_loss: 0.3827 - val_acc: 0.8651\n",
            "Epoch 5/10\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.4915 - acc: 0.8190Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 107us/sample - loss: 0.3081 - acc: 0.8698\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4916 - acc: 0.8189 - val_loss: 0.3724 - val_acc: 0.8698\n",
            "Epoch 6/10\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.4741 - acc: 0.8236Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 104us/sample - loss: 0.3311 - acc: 0.8746\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4742 - acc: 0.8235 - val_loss: 0.3619 - val_acc: 0.8746\n",
            "Epoch 7/10\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8302Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 109us/sample - loss: 0.2885 - acc: 0.8726\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4613 - acc: 0.8303 - val_loss: 0.3617 - val_acc: 0.8726\n",
            "Epoch 8/10\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.8350Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 108us/sample - loss: 0.3090 - acc: 0.8819\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4468 - acc: 0.8350 - val_loss: 0.3448 - val_acc: 0.8819\n",
            "Epoch 9/10\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.4394 - acc: 0.8374Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 111us/sample - loss: 0.2731 - acc: 0.8796\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4395 - acc: 0.8374 - val_loss: 0.3415 - val_acc: 0.8796\n",
            "Epoch 10/10\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.4321 - acc: 0.8398Epoch 1/10\n",
            "10000/1875 [================================================================================================================================================================] - 1s 109us/sample - loss: 0.2636 - acc: 0.8793\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4322 - acc: 0.8397 - val_loss: 0.3480 - val_acc: 0.8793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb3720245c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MwQQW5iOJjwq"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c1SrtBEPJjwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "635c94e3-f6bc-4d08-a54c-659855e310ac"
      },
      "source": [
        "scores = model1.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Train Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 89.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZBwVWNQC2qZD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95ec86b1-13ff-4198-812d-dc8943850b3e"
      },
      "source": [
        "scores = model1.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 87.93%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8KXqmUDW2rM1"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8mja6OgQ3L18"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6HzVTPUM3WZJ"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PPM558TX4KMb",
        "colab": {}
      },
      "source": [
        "#already imported in this notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W6hicLwP4SqY"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NQ1WzrXd4WNk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2bf86906-a0c9-4414-be17-42d59c7dcc63"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sw06z9NMHMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "494fa8ce-0193-4ea0-9c4d-194a7f7113c3"
      },
      "source": [
        "print('Train: X=%s, y=%s' % (xtrain.shape, ytrain.shape))\n",
        "print('Test: X=%s, y=%s' % (xtest.shape, ytest.shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n",
            "Test: X=(10000, 32, 32, 3), y=(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzOlpOmFMOBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = xtrain / 255.0\n",
        "xtest = xtest / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZLo2HPkMYMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain=xtrain.reshape(xtrain.shape[0],32,32,3).astype('float32')\n",
        "xtest=xtest.reshape(xtest.shape[0],32,32,3).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JN3vYYhK4W0u"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JJbekTKi4cmM",
        "colab": {}
      },
      "source": [
        "data_gen = ImageDataGenerator(rotation_range=30,height_shift_range=0.5,width_shift_range=0.9,horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e-SLtUhC4dK2"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CSw8Bv2_4hb0",
        "colab": {}
      },
      "source": [
        "data_gen.fit(xtrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gYyF-P8O4jQ8"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mXug4z234mwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "9b864767-2688-481d-eee3-0023902fc597"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = data_gen.flow(xtrain[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqSbdSiqppJJblGrSraSSSiq5Rfm/uMWjCo0LtN4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}