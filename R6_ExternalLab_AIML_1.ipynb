{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_ExternalLab_AIML-1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYk8NG3yOIT9",
        "colab_type": "text"
      },
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFO6PuxzOIT_",
        "colab_type": "text"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNjNImfOIUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f29cf36d-da04-42fe-daae-032523df16c0"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9C4aAIGOIUH",
        "colab_type": "code",
        "outputId": "f780bee7-aea0-4267-e03e-dc9c29862a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcoZBStrOIUQ",
        "colab_type": "text"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA1WsFSeOIUS",
        "colab_type": "code",
        "outputId": "4708ed56-de1b-4674-9ac1-397b019a9250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnbx7TyQOIUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbiHj5YPOIUc",
        "colab_type": "code",
        "outputId": "b1cf32b0-d53a-4343-9993-1bd08b4a0afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDAYzkwyOIUj",
        "colab_type": "text"
      },
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlfYlANOIUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY1=tf.keras.utils.to_categorical(trainY,num_classes=10)\n",
        "testY1=tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RHV3b9mzOIUq",
        "colab_type": "code",
        "outputId": "f9cb43a8-4d41-4400-a1ef-b4a2e4e6f08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "print(trainY1.shape)\n",
        "print('First 5 examples now are: ', trainY1[0:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "('First 5 examples now are: ', array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwhQ8e7VOIUw",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDML2OoOIUx",
        "colab_type": "code",
        "outputId": "1e9640c7-e19d-468d-fad3-fb7f0e7a99e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqVIQlMSxTro",
        "colab_type": "code",
        "outputId": "de497723-ee26-4e9b-a827-6b7295689ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "for i in range(10):\n",
        "\tpyplot.subplot(1,10,0+1+i)\n",
        "\tpyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n",
        "pyplot.show()\n",
        "print(\"label for each of the above image:\")\n",
        "print(trainY[0:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAA/CAYAAADwizNIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDO2nGbP3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "label for each of the above image:\n",
            "[9 0 0 3 0 2 7 2 5 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4TbJGeSOIU4",
        "colab_type": "text"
      },
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac06XZZTOIU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQpLv3aOIU_",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59C_-IgOIVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = tf.keras.utils.normalize(trainX,axis=1) \n",
        "testX = tf.keras.utils.normalize(testX,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQqDCSIWPGEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98a9a036-d1b0-4f38-ab1f-3c8dceaccd4c"
      },
      "source": [
        "model.fit(trainX,trainY1,validation_data=(testX, testY1),epochs=100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 4s 69us/sample - loss: 1.2777 - accuracy: 0.6577 - val_loss: 0.9442 - val_accuracy: 0.7181\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.8351 - accuracy: 0.7485 - val_loss: 0.7832 - val_accuracy: 0.7521\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.7281 - accuracy: 0.7694 - val_loss: 0.7140 - val_accuracy: 0.7663\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6735 - accuracy: 0.7821 - val_loss: 0.6742 - val_accuracy: 0.7749\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.6387 - accuracy: 0.7894 - val_loss: 0.6460 - val_accuracy: 0.7803\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.6140 - accuracy: 0.7948 - val_loss: 0.6255 - val_accuracy: 0.7870\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.5952 - accuracy: 0.7991 - val_loss: 0.6098 - val_accuracy: 0.7912\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.5802 - accuracy: 0.8032 - val_loss: 0.5971 - val_accuracy: 0.7952\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.5680 - accuracy: 0.8065 - val_loss: 0.5860 - val_accuracy: 0.7981\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.5576 - accuracy: 0.8093 - val_loss: 0.5772 - val_accuracy: 0.8012\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.5487 - accuracy: 0.8115 - val_loss: 0.5694 - val_accuracy: 0.8035\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.5409 - accuracy: 0.8140 - val_loss: 0.5626 - val_accuracy: 0.8071\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.5340 - accuracy: 0.8159 - val_loss: 0.5569 - val_accuracy: 0.8087\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.5280 - accuracy: 0.8180 - val_loss: 0.5514 - val_accuracy: 0.8106\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.5225 - accuracy: 0.8188 - val_loss: 0.5462 - val_accuracy: 0.8128\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.5173 - accuracy: 0.8207 - val_loss: 0.5414 - val_accuracy: 0.8151\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.5128 - accuracy: 0.8223 - val_loss: 0.5375 - val_accuracy: 0.8157\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.5085 - accuracy: 0.8238 - val_loss: 0.5339 - val_accuracy: 0.8165\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.5045 - accuracy: 0.8241 - val_loss: 0.5301 - val_accuracy: 0.8199\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.5009 - accuracy: 0.8257 - val_loss: 0.5270 - val_accuracy: 0.8195\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4975 - accuracy: 0.8271 - val_loss: 0.5242 - val_accuracy: 0.8220\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4943 - accuracy: 0.8285 - val_loss: 0.5217 - val_accuracy: 0.8205\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4913 - accuracy: 0.8295 - val_loss: 0.5199 - val_accuracy: 0.8209\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4885 - accuracy: 0.8299 - val_loss: 0.5162 - val_accuracy: 0.8234\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4858 - accuracy: 0.8312 - val_loss: 0.5138 - val_accuracy: 0.8241\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4833 - accuracy: 0.8311 - val_loss: 0.5116 - val_accuracy: 0.8251\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4809 - accuracy: 0.8325 - val_loss: 0.5098 - val_accuracy: 0.8252\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4786 - accuracy: 0.8332 - val_loss: 0.5075 - val_accuracy: 0.8265\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4764 - accuracy: 0.8335 - val_loss: 0.5060 - val_accuracy: 0.8278\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4744 - accuracy: 0.8348 - val_loss: 0.5037 - val_accuracy: 0.8276\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4723 - accuracy: 0.8355 - val_loss: 0.5021 - val_accuracy: 0.8293\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4704 - accuracy: 0.8359 - val_loss: 0.5006 - val_accuracy: 0.8296\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4685 - accuracy: 0.8364 - val_loss: 0.4987 - val_accuracy: 0.8306\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4669 - accuracy: 0.8372 - val_loss: 0.4976 - val_accuracy: 0.8298\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4652 - accuracy: 0.8374 - val_loss: 0.4957 - val_accuracy: 0.8306\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4636 - accuracy: 0.8382 - val_loss: 0.4948 - val_accuracy: 0.8319\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4620 - accuracy: 0.8393 - val_loss: 0.4935 - val_accuracy: 0.8306\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4604 - accuracy: 0.8398 - val_loss: 0.4918 - val_accuracy: 0.8321\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4590 - accuracy: 0.8404 - val_loss: 0.4909 - val_accuracy: 0.8314\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4576 - accuracy: 0.8404 - val_loss: 0.4894 - val_accuracy: 0.8323\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4563 - accuracy: 0.8408 - val_loss: 0.4884 - val_accuracy: 0.8334\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4549 - accuracy: 0.8417 - val_loss: 0.4875 - val_accuracy: 0.8324\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4537 - accuracy: 0.8422 - val_loss: 0.4863 - val_accuracy: 0.8338\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4525 - accuracy: 0.8424 - val_loss: 0.4851 - val_accuracy: 0.8343\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4513 - accuracy: 0.8424 - val_loss: 0.4843 - val_accuracy: 0.8347\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4501 - accuracy: 0.8432 - val_loss: 0.4833 - val_accuracy: 0.8345\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4490 - accuracy: 0.8436 - val_loss: 0.4825 - val_accuracy: 0.8357\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4478 - accuracy: 0.8437 - val_loss: 0.4812 - val_accuracy: 0.8357\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4468 - accuracy: 0.8446 - val_loss: 0.4804 - val_accuracy: 0.8363\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4458 - accuracy: 0.8449 - val_loss: 0.4799 - val_accuracy: 0.8349\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4447 - accuracy: 0.8446 - val_loss: 0.4787 - val_accuracy: 0.8364\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4437 - accuracy: 0.8455 - val_loss: 0.4779 - val_accuracy: 0.8363\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4427 - accuracy: 0.8455 - val_loss: 0.4775 - val_accuracy: 0.8365\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4419 - accuracy: 0.8460 - val_loss: 0.4766 - val_accuracy: 0.8364\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4409 - accuracy: 0.8467 - val_loss: 0.4759 - val_accuracy: 0.8368\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4400 - accuracy: 0.8465 - val_loss: 0.4752 - val_accuracy: 0.8360\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4392 - accuracy: 0.8461 - val_loss: 0.4742 - val_accuracy: 0.8367\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4383 - accuracy: 0.8467 - val_loss: 0.4736 - val_accuracy: 0.8377\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4375 - accuracy: 0.8475 - val_loss: 0.4729 - val_accuracy: 0.8370\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4367 - accuracy: 0.8470 - val_loss: 0.4723 - val_accuracy: 0.8381\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4358 - accuracy: 0.8481 - val_loss: 0.4717 - val_accuracy: 0.8375\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4351 - accuracy: 0.8481 - val_loss: 0.4711 - val_accuracy: 0.8378\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4344 - accuracy: 0.8482 - val_loss: 0.4703 - val_accuracy: 0.8388\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4336 - accuracy: 0.8482 - val_loss: 0.4699 - val_accuracy: 0.8392\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4329 - accuracy: 0.8490 - val_loss: 0.4692 - val_accuracy: 0.8397\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4321 - accuracy: 0.8492 - val_loss: 0.4688 - val_accuracy: 0.8397\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4315 - accuracy: 0.8494 - val_loss: 0.4681 - val_accuracy: 0.8395\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4307 - accuracy: 0.8490 - val_loss: 0.4675 - val_accuracy: 0.8402\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4300 - accuracy: 0.8498 - val_loss: 0.4672 - val_accuracy: 0.8397\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4294 - accuracy: 0.8497 - val_loss: 0.4669 - val_accuracy: 0.8404\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4287 - accuracy: 0.8499 - val_loss: 0.4667 - val_accuracy: 0.8399\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4281 - accuracy: 0.8504 - val_loss: 0.4660 - val_accuracy: 0.8389\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4275 - accuracy: 0.8507 - val_loss: 0.4652 - val_accuracy: 0.8408\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4269 - accuracy: 0.8502 - val_loss: 0.4646 - val_accuracy: 0.8397\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4262 - accuracy: 0.8506 - val_loss: 0.4641 - val_accuracy: 0.8401\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4257 - accuracy: 0.8509 - val_loss: 0.4639 - val_accuracy: 0.8395\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4251 - accuracy: 0.8514 - val_loss: 0.4633 - val_accuracy: 0.8408\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4245 - accuracy: 0.8511 - val_loss: 0.4628 - val_accuracy: 0.8401\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4239 - accuracy: 0.8516 - val_loss: 0.4627 - val_accuracy: 0.8414\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4234 - accuracy: 0.8516 - val_loss: 0.4623 - val_accuracy: 0.8402\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4227 - accuracy: 0.8520 - val_loss: 0.4616 - val_accuracy: 0.8411\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4223 - accuracy: 0.8520 - val_loss: 0.4615 - val_accuracy: 0.8412\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4219 - accuracy: 0.8519 - val_loss: 0.4607 - val_accuracy: 0.8418\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4214 - accuracy: 0.8522 - val_loss: 0.4603 - val_accuracy: 0.8419\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4208 - accuracy: 0.8526 - val_loss: 0.4598 - val_accuracy: 0.8406\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4203 - accuracy: 0.8530 - val_loss: 0.4596 - val_accuracy: 0.8420\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4198 - accuracy: 0.8529 - val_loss: 0.4593 - val_accuracy: 0.8423\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4193 - accuracy: 0.8533 - val_loss: 0.4589 - val_accuracy: 0.8411\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4187 - accuracy: 0.8535 - val_loss: 0.4591 - val_accuracy: 0.8413\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4184 - accuracy: 0.8537 - val_loss: 0.4584 - val_accuracy: 0.8428\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4178 - accuracy: 0.8543 - val_loss: 0.4578 - val_accuracy: 0.8423\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4175 - accuracy: 0.8540 - val_loss: 0.4575 - val_accuracy: 0.8422\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4170 - accuracy: 0.8539 - val_loss: 0.4572 - val_accuracy: 0.8433\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4166 - accuracy: 0.8543 - val_loss: 0.4569 - val_accuracy: 0.8421\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4160 - accuracy: 0.8541 - val_loss: 0.4566 - val_accuracy: 0.8428\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4157 - accuracy: 0.8545 - val_loss: 0.4562 - val_accuracy: 0.8427\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4152 - accuracy: 0.8554 - val_loss: 0.4560 - val_accuracy: 0.8427\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4148 - accuracy: 0.8548 - val_loss: 0.4555 - val_accuracy: 0.8431\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4144 - accuracy: 0.8554 - val_loss: 0.4552 - val_accuracy: 0.8432\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4140 - accuracy: 0.8550 - val_loss: 0.4549 - val_accuracy: 0.8431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff98c223190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzDtGwDOIVF",
        "colab_type": "text"
      },
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndfpdidOIVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwk3T5LJOIVN",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLR8tcBOIVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa50e259-52c1-4c5b-e958-fba3d3108656"
      },
      "source": [
        "model.fit(trainX,trainY1,validation_data=(testX,testY1), epochs=100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.5606 - accuracy: 0.8016 - val_loss: 0.4919 - val_accuracy: 0.8312\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4582 - accuracy: 0.8375 - val_loss: 0.4627 - val_accuracy: 0.8419\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4352 - accuracy: 0.8471 - val_loss: 0.4555 - val_accuracy: 0.8453\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4238 - accuracy: 0.8493 - val_loss: 0.4509 - val_accuracy: 0.8467\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4192 - accuracy: 0.8502 - val_loss: 0.4466 - val_accuracy: 0.8454\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4144 - accuracy: 0.8540 - val_loss: 0.4465 - val_accuracy: 0.8457\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4079 - accuracy: 0.8547 - val_loss: 0.4461 - val_accuracy: 0.8470\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4071 - accuracy: 0.8565 - val_loss: 0.4429 - val_accuracy: 0.8462\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4018 - accuracy: 0.8583 - val_loss: 0.4430 - val_accuracy: 0.8455\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3989 - accuracy: 0.8579 - val_loss: 0.4427 - val_accuracy: 0.8447\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3978 - accuracy: 0.8579 - val_loss: 0.4447 - val_accuracy: 0.8453\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3933 - accuracy: 0.8593 - val_loss: 0.4432 - val_accuracy: 0.8460\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3950 - accuracy: 0.8587 - val_loss: 0.4411 - val_accuracy: 0.8463\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3921 - accuracy: 0.8613 - val_loss: 0.4479 - val_accuracy: 0.8430\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3918 - accuracy: 0.8594 - val_loss: 0.4432 - val_accuracy: 0.8456\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3885 - accuracy: 0.8615 - val_loss: 0.4448 - val_accuracy: 0.8450\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3886 - accuracy: 0.8612 - val_loss: 0.4436 - val_accuracy: 0.8454\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3877 - accuracy: 0.8605 - val_loss: 0.4458 - val_accuracy: 0.8473\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3860 - accuracy: 0.8625 - val_loss: 0.4411 - val_accuracy: 0.8463\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3872 - accuracy: 0.8618 - val_loss: 0.4421 - val_accuracy: 0.8470\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3845 - accuracy: 0.8628 - val_loss: 0.4450 - val_accuracy: 0.8450\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3838 - accuracy: 0.8632 - val_loss: 0.4443 - val_accuracy: 0.8472\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3830 - accuracy: 0.8626 - val_loss: 0.4444 - val_accuracy: 0.8457\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3823 - accuracy: 0.8621 - val_loss: 0.4478 - val_accuracy: 0.8450\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3818 - accuracy: 0.8623 - val_loss: 0.4440 - val_accuracy: 0.8464\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3826 - accuracy: 0.8613 - val_loss: 0.4478 - val_accuracy: 0.8443\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3816 - accuracy: 0.8641 - val_loss: 0.4459 - val_accuracy: 0.8469\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3784 - accuracy: 0.8637 - val_loss: 0.4485 - val_accuracy: 0.8473\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3805 - accuracy: 0.8630 - val_loss: 0.4427 - val_accuracy: 0.8476\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3805 - accuracy: 0.8629 - val_loss: 0.4490 - val_accuracy: 0.8445\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3791 - accuracy: 0.8643 - val_loss: 0.4470 - val_accuracy: 0.8455\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3789 - accuracy: 0.8647 - val_loss: 0.4510 - val_accuracy: 0.8434\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3804 - accuracy: 0.8632 - val_loss: 0.4492 - val_accuracy: 0.8460\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3779 - accuracy: 0.8634 - val_loss: 0.4480 - val_accuracy: 0.8463\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3773 - accuracy: 0.8635 - val_loss: 0.4510 - val_accuracy: 0.8453\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3788 - accuracy: 0.8636 - val_loss: 0.4516 - val_accuracy: 0.8440\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3756 - accuracy: 0.8644 - val_loss: 0.4474 - val_accuracy: 0.8456\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3785 - accuracy: 0.8638 - val_loss: 0.4532 - val_accuracy: 0.8447\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3771 - accuracy: 0.8631 - val_loss: 0.4493 - val_accuracy: 0.8468\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3773 - accuracy: 0.8633 - val_loss: 0.4496 - val_accuracy: 0.8453\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3753 - accuracy: 0.8649 - val_loss: 0.4494 - val_accuracy: 0.8459\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3743 - accuracy: 0.8640 - val_loss: 0.4481 - val_accuracy: 0.8452\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3754 - accuracy: 0.8648 - val_loss: 0.4470 - val_accuracy: 0.8458\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3748 - accuracy: 0.8654 - val_loss: 0.4506 - val_accuracy: 0.8462\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3766 - accuracy: 0.8644 - val_loss: 0.4518 - val_accuracy: 0.8458\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3761 - accuracy: 0.8650 - val_loss: 0.4505 - val_accuracy: 0.8444\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3754 - accuracy: 0.8645 - val_loss: 0.4568 - val_accuracy: 0.8436\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3735 - accuracy: 0.8650 - val_loss: 0.4512 - val_accuracy: 0.8445\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3745 - accuracy: 0.8639 - val_loss: 0.4515 - val_accuracy: 0.8457\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3726 - accuracy: 0.8653 - val_loss: 0.4508 - val_accuracy: 0.8460\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3738 - accuracy: 0.8657 - val_loss: 0.4511 - val_accuracy: 0.8436\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3737 - accuracy: 0.8641 - val_loss: 0.4490 - val_accuracy: 0.8457\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3741 - accuracy: 0.8650 - val_loss: 0.4524 - val_accuracy: 0.8452\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3732 - accuracy: 0.8661 - val_loss: 0.4548 - val_accuracy: 0.8453\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3743 - accuracy: 0.8644 - val_loss: 0.4569 - val_accuracy: 0.8433\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3738 - accuracy: 0.8645 - val_loss: 0.4590 - val_accuracy: 0.8451\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3727 - accuracy: 0.8664 - val_loss: 0.4509 - val_accuracy: 0.8465\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3708 - accuracy: 0.8667 - val_loss: 0.4526 - val_accuracy: 0.8455\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3737 - accuracy: 0.8652 - val_loss: 0.4548 - val_accuracy: 0.8461\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3697 - accuracy: 0.8659 - val_loss: 0.4569 - val_accuracy: 0.8437\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3705 - accuracy: 0.8675 - val_loss: 0.4529 - val_accuracy: 0.8439\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3718 - accuracy: 0.8642 - val_loss: 0.4537 - val_accuracy: 0.8448\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3724 - accuracy: 0.8653 - val_loss: 0.4534 - val_accuracy: 0.8486\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3720 - accuracy: 0.8647 - val_loss: 0.4591 - val_accuracy: 0.8448\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3732 - accuracy: 0.8660 - val_loss: 0.4565 - val_accuracy: 0.8459\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3724 - accuracy: 0.8664 - val_loss: 0.4562 - val_accuracy: 0.8442\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3713 - accuracy: 0.8657 - val_loss: 0.4573 - val_accuracy: 0.8438\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3698 - accuracy: 0.8655 - val_loss: 0.4582 - val_accuracy: 0.8434\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3700 - accuracy: 0.8658 - val_loss: 0.4539 - val_accuracy: 0.8444\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3712 - accuracy: 0.8653 - val_loss: 0.4561 - val_accuracy: 0.8470\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3697 - accuracy: 0.8664 - val_loss: 0.4544 - val_accuracy: 0.8482\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3718 - accuracy: 0.8664 - val_loss: 0.4555 - val_accuracy: 0.8459\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3695 - accuracy: 0.8660 - val_loss: 0.4565 - val_accuracy: 0.8456\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3705 - accuracy: 0.8654 - val_loss: 0.4563 - val_accuracy: 0.8460\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3721 - accuracy: 0.8653 - val_loss: 0.4545 - val_accuracy: 0.8452\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3696 - accuracy: 0.8667 - val_loss: 0.4565 - val_accuracy: 0.8457\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3709 - accuracy: 0.8662 - val_loss: 0.4566 - val_accuracy: 0.8437\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3704 - accuracy: 0.8652 - val_loss: 0.4562 - val_accuracy: 0.8442\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3697 - accuracy: 0.8668 - val_loss: 0.4590 - val_accuracy: 0.8437\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3702 - accuracy: 0.8655 - val_loss: 0.4562 - val_accuracy: 0.8449\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3700 - accuracy: 0.8673 - val_loss: 0.4569 - val_accuracy: 0.8452\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3679 - accuracy: 0.8666 - val_loss: 0.4562 - val_accuracy: 0.8462\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3710 - accuracy: 0.8666 - val_loss: 0.4565 - val_accuracy: 0.8445\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3701 - accuracy: 0.8654 - val_loss: 0.4569 - val_accuracy: 0.8444\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3693 - accuracy: 0.8675 - val_loss: 0.4567 - val_accuracy: 0.8463\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3697 - accuracy: 0.8653 - val_loss: 0.4597 - val_accuracy: 0.8433\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3698 - accuracy: 0.8671 - val_loss: 0.4551 - val_accuracy: 0.8453\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3679 - accuracy: 0.8655 - val_loss: 0.4599 - val_accuracy: 0.8458\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3688 - accuracy: 0.8663 - val_loss: 0.4579 - val_accuracy: 0.8452\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3707 - accuracy: 0.8659 - val_loss: 0.4558 - val_accuracy: 0.8452\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3692 - accuracy: 0.8653 - val_loss: 0.4539 - val_accuracy: 0.8457\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3677 - accuracy: 0.8658 - val_loss: 0.4610 - val_accuracy: 0.8439\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3686 - accuracy: 0.8673 - val_loss: 0.4589 - val_accuracy: 0.8423\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3693 - accuracy: 0.8659 - val_loss: 0.4585 - val_accuracy: 0.8439\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3692 - accuracy: 0.8662 - val_loss: 0.4583 - val_accuracy: 0.8446\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3677 - accuracy: 0.8678 - val_loss: 0.4592 - val_accuracy: 0.8461\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3682 - accuracy: 0.8648 - val_loss: 0.4598 - val_accuracy: 0.8451\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3685 - accuracy: 0.8665 - val_loss: 0.4612 - val_accuracy: 0.8447\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3679 - accuracy: 0.8657 - val_loss: 0.4598 - val_accuracy: 0.8455\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3698 - accuracy: 0.8659 - val_loss: 0.4620 - val_accuracy: 0.8452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff981c78490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py-KwkmjOIVU",
        "colab_type": "text"
      },
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLXUE9jWOIVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'],learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJUqA5T4OIVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "485290d8-a7fe-4c1a-d8ab-f80ab0d8a503"
      },
      "source": [
        "model.fit(trainX,trainY1,validation_data=(testX,testY1), epochs=100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.5742 - accuracy: 0.7985 - val_loss: 0.4951 - val_accuracy: 0.8334\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4613 - accuracy: 0.8386 - val_loss: 0.4693 - val_accuracy: 0.8395\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4358 - accuracy: 0.8458 - val_loss: 0.4599 - val_accuracy: 0.8408\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4264 - accuracy: 0.8493 - val_loss: 0.4524 - val_accuracy: 0.8453\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4144 - accuracy: 0.8529 - val_loss: 0.4519 - val_accuracy: 0.8434\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4130 - accuracy: 0.8543 - val_loss: 0.4507 - val_accuracy: 0.8450\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.4067 - accuracy: 0.8562 - val_loss: 0.4502 - val_accuracy: 0.8443\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.4045 - accuracy: 0.8564 - val_loss: 0.4462 - val_accuracy: 0.8470\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4010 - accuracy: 0.8577 - val_loss: 0.4450 - val_accuracy: 0.8450\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3991 - accuracy: 0.8568 - val_loss: 0.4435 - val_accuracy: 0.8460\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3976 - accuracy: 0.8597 - val_loss: 0.4438 - val_accuracy: 0.8463\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3953 - accuracy: 0.8591 - val_loss: 0.4429 - val_accuracy: 0.8457\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3912 - accuracy: 0.8600 - val_loss: 0.4448 - val_accuracy: 0.8455\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3919 - accuracy: 0.8590 - val_loss: 0.4473 - val_accuracy: 0.8463\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3891 - accuracy: 0.8608 - val_loss: 0.4449 - val_accuracy: 0.8450\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3902 - accuracy: 0.8623 - val_loss: 0.4460 - val_accuracy: 0.8443\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3869 - accuracy: 0.8621 - val_loss: 0.4460 - val_accuracy: 0.8445\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3871 - accuracy: 0.8606 - val_loss: 0.4464 - val_accuracy: 0.8446\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3876 - accuracy: 0.8615 - val_loss: 0.4430 - val_accuracy: 0.8480\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3869 - accuracy: 0.8628 - val_loss: 0.4500 - val_accuracy: 0.8453\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3845 - accuracy: 0.8622 - val_loss: 0.4503 - val_accuracy: 0.8463\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3851 - accuracy: 0.8620 - val_loss: 0.4446 - val_accuracy: 0.8457\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3831 - accuracy: 0.8628 - val_loss: 0.4451 - val_accuracy: 0.8468\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3824 - accuracy: 0.8635 - val_loss: 0.4483 - val_accuracy: 0.8466\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3818 - accuracy: 0.8631 - val_loss: 0.4565 - val_accuracy: 0.8426\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3830 - accuracy: 0.8634 - val_loss: 0.4460 - val_accuracy: 0.8464\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3814 - accuracy: 0.8641 - val_loss: 0.4451 - val_accuracy: 0.8465\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3802 - accuracy: 0.8644 - val_loss: 0.4481 - val_accuracy: 0.8459\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3799 - accuracy: 0.8629 - val_loss: 0.4516 - val_accuracy: 0.8474\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3793 - accuracy: 0.8629 - val_loss: 0.4468 - val_accuracy: 0.8464\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3777 - accuracy: 0.8636 - val_loss: 0.4462 - val_accuracy: 0.8464\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3800 - accuracy: 0.8627 - val_loss: 0.4483 - val_accuracy: 0.8440\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3781 - accuracy: 0.8636 - val_loss: 0.4463 - val_accuracy: 0.8462\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3758 - accuracy: 0.8648 - val_loss: 0.4475 - val_accuracy: 0.8444\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3766 - accuracy: 0.8638 - val_loss: 0.4498 - val_accuracy: 0.8468\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3755 - accuracy: 0.8649 - val_loss: 0.4479 - val_accuracy: 0.8463\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3758 - accuracy: 0.8644 - val_loss: 0.4485 - val_accuracy: 0.8449\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3775 - accuracy: 0.8650 - val_loss: 0.4482 - val_accuracy: 0.8460\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3763 - accuracy: 0.8644 - val_loss: 0.4510 - val_accuracy: 0.8449\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3765 - accuracy: 0.8640 - val_loss: 0.4509 - val_accuracy: 0.8462\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3739 - accuracy: 0.8666 - val_loss: 0.4521 - val_accuracy: 0.8452\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3761 - accuracy: 0.8648 - val_loss: 0.4553 - val_accuracy: 0.8443\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3755 - accuracy: 0.8638 - val_loss: 0.4559 - val_accuracy: 0.8443\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3770 - accuracy: 0.8634 - val_loss: 0.4490 - val_accuracy: 0.8474\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3757 - accuracy: 0.8654 - val_loss: 0.4520 - val_accuracy: 0.8443\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3746 - accuracy: 0.8652 - val_loss: 0.4528 - val_accuracy: 0.8451\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3750 - accuracy: 0.8645 - val_loss: 0.4530 - val_accuracy: 0.8441\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3722 - accuracy: 0.8673 - val_loss: 0.4493 - val_accuracy: 0.8467\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3746 - accuracy: 0.8642 - val_loss: 0.4514 - val_accuracy: 0.8444\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3742 - accuracy: 0.8644 - val_loss: 0.4516 - val_accuracy: 0.8458\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3709 - accuracy: 0.8658 - val_loss: 0.4550 - val_accuracy: 0.8449\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3740 - accuracy: 0.8660 - val_loss: 0.4567 - val_accuracy: 0.8427\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3724 - accuracy: 0.8669 - val_loss: 0.4547 - val_accuracy: 0.8425\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3744 - accuracy: 0.8645 - val_loss: 0.4586 - val_accuracy: 0.8429\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3728 - accuracy: 0.8651 - val_loss: 0.4560 - val_accuracy: 0.8431\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3727 - accuracy: 0.8658 - val_loss: 0.4548 - val_accuracy: 0.8460\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3727 - accuracy: 0.8657 - val_loss: 0.4563 - val_accuracy: 0.8421\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3719 - accuracy: 0.8647 - val_loss: 0.4594 - val_accuracy: 0.8447\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3742 - accuracy: 0.8663 - val_loss: 0.4545 - val_accuracy: 0.8438\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3713 - accuracy: 0.8651 - val_loss: 0.4628 - val_accuracy: 0.8442\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3735 - accuracy: 0.8655 - val_loss: 0.4543 - val_accuracy: 0.8461\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3708 - accuracy: 0.8664 - val_loss: 0.4522 - val_accuracy: 0.8452\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3727 - accuracy: 0.8660 - val_loss: 0.4542 - val_accuracy: 0.8455\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3714 - accuracy: 0.8664 - val_loss: 0.4555 - val_accuracy: 0.8434\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3699 - accuracy: 0.8669 - val_loss: 0.4550 - val_accuracy: 0.8447\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3726 - accuracy: 0.8669 - val_loss: 0.4566 - val_accuracy: 0.8438\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3710 - accuracy: 0.8655 - val_loss: 0.4559 - val_accuracy: 0.8451\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3685 - accuracy: 0.8674 - val_loss: 0.4559 - val_accuracy: 0.8454\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3710 - accuracy: 0.8661 - val_loss: 0.4570 - val_accuracy: 0.8450\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3691 - accuracy: 0.8661 - val_loss: 0.4584 - val_accuracy: 0.8439\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3707 - accuracy: 0.8646 - val_loss: 0.4569 - val_accuracy: 0.8426\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.3693 - accuracy: 0.8659 - val_loss: 0.4537 - val_accuracy: 0.8462\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3705 - accuracy: 0.8643 - val_loss: 0.4586 - val_accuracy: 0.8429\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3704 - accuracy: 0.8662 - val_loss: 0.4602 - val_accuracy: 0.8431\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3712 - accuracy: 0.8666 - val_loss: 0.4627 - val_accuracy: 0.8443\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3693 - accuracy: 0.8669 - val_loss: 0.4573 - val_accuracy: 0.8444\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3708 - accuracy: 0.8667 - val_loss: 0.4632 - val_accuracy: 0.8407\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3688 - accuracy: 0.8666 - val_loss: 0.4566 - val_accuracy: 0.8444\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3690 - accuracy: 0.8660 - val_loss: 0.4595 - val_accuracy: 0.8440\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3687 - accuracy: 0.8655 - val_loss: 0.4652 - val_accuracy: 0.8429\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3693 - accuracy: 0.8652 - val_loss: 0.4556 - val_accuracy: 0.8440\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3691 - accuracy: 0.8673 - val_loss: 0.4568 - val_accuracy: 0.8437\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3693 - accuracy: 0.8654 - val_loss: 0.4578 - val_accuracy: 0.8451\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3677 - accuracy: 0.8657 - val_loss: 0.4577 - val_accuracy: 0.8445\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3687 - accuracy: 0.8669 - val_loss: 0.4585 - val_accuracy: 0.8413\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3679 - accuracy: 0.8677 - val_loss: 0.4568 - val_accuracy: 0.8455\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3703 - accuracy: 0.8665 - val_loss: 0.4590 - val_accuracy: 0.8441\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3696 - accuracy: 0.8657 - val_loss: 0.4575 - val_accuracy: 0.8431\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3700 - accuracy: 0.8663 - val_loss: 0.4562 - val_accuracy: 0.8444\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3678 - accuracy: 0.8659 - val_loss: 0.4591 - val_accuracy: 0.8428\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3708 - accuracy: 0.8657 - val_loss: 0.4601 - val_accuracy: 0.8438\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3688 - accuracy: 0.8659 - val_loss: 0.4578 - val_accuracy: 0.8451\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3677 - accuracy: 0.8668 - val_loss: 0.4637 - val_accuracy: 0.8427\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3683 - accuracy: 0.8671 - val_loss: 0.4648 - val_accuracy: 0.8417\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3690 - accuracy: 0.8651 - val_loss: 0.4619 - val_accuracy: 0.8436\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3695 - accuracy: 0.8649 - val_loss: 0.4581 - val_accuracy: 0.8459\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3695 - accuracy: 0.8665 - val_loss: 0.4603 - val_accuracy: 0.8438\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3689 - accuracy: 0.8655 - val_loss: 0.4578 - val_accuracy: 0.8438\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3683 - accuracy: 0.8656 - val_loss: 0.4645 - val_accuracy: 0.8417\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3691 - accuracy: 0.8665 - val_loss: 0.4609 - val_accuracy: 0.8419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff980f2cd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CSqKvpOIVk",
        "colab_type": "text"
      },
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGAad54JOIVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'],learning_rate=0.03)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ7oIymROIVp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c5c60c0-91cf-43e8-9c9f-ec7ec001c394"
      },
      "source": [
        "model.fit(trainX,trainY1,validation_data=(testX,testY1), epochs=100)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 1.5462 - accuracy: 0.6094 - val_loss: 1.0146 - val_accuracy: 0.6954\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.8398 - accuracy: 0.7379 - val_loss: 0.7182 - val_accuracy: 0.7569\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.6624 - accuracy: 0.7718 - val_loss: 0.6134 - val_accuracy: 0.7814\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.5852 - accuracy: 0.7926 - val_loss: 0.5585 - val_accuracy: 0.8008\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.5392 - accuracy: 0.8089 - val_loss: 0.5233 - val_accuracy: 0.8146\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.5081 - accuracy: 0.8199 - val_loss: 0.4981 - val_accuracy: 0.8227\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4831 - accuracy: 0.8282 - val_loss: 0.4780 - val_accuracy: 0.8323\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.4656 - accuracy: 0.8331 - val_loss: 0.4643 - val_accuracy: 0.8387\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.4515 - accuracy: 0.8390 - val_loss: 0.4551 - val_accuracy: 0.8403\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.4415 - accuracy: 0.8415 - val_loss: 0.4437 - val_accuracy: 0.8444\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.4289 - accuracy: 0.8461 - val_loss: 0.4351 - val_accuracy: 0.8479\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.4204 - accuracy: 0.8491 - val_loss: 0.4280 - val_accuracy: 0.8499\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 7s 108us/sample - loss: 0.4119 - accuracy: 0.8518 - val_loss: 0.4214 - val_accuracy: 0.8538\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.4038 - accuracy: 0.8554 - val_loss: 0.4162 - val_accuracy: 0.8534\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.3976 - accuracy: 0.8565 - val_loss: 0.4104 - val_accuracy: 0.8560\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.3914 - accuracy: 0.8597 - val_loss: 0.4055 - val_accuracy: 0.8577\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3866 - accuracy: 0.8612 - val_loss: 0.4025 - val_accuracy: 0.8581\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3804 - accuracy: 0.8628 - val_loss: 0.3979 - val_accuracy: 0.8599\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3757 - accuracy: 0.8644 - val_loss: 0.3939 - val_accuracy: 0.8617\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3695 - accuracy: 0.8666 - val_loss: 0.3921 - val_accuracy: 0.8633\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3678 - accuracy: 0.8677 - val_loss: 0.3859 - val_accuracy: 0.8639\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 7s 108us/sample - loss: 0.3622 - accuracy: 0.8699 - val_loss: 0.3834 - val_accuracy: 0.8644\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.3576 - accuracy: 0.8716 - val_loss: 0.3817 - val_accuracy: 0.8632\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.3539 - accuracy: 0.8719 - val_loss: 0.3784 - val_accuracy: 0.8659\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3523 - accuracy: 0.8725 - val_loss: 0.3773 - val_accuracy: 0.8667\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.3470 - accuracy: 0.8740 - val_loss: 0.3759 - val_accuracy: 0.8657\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.3446 - accuracy: 0.8752 - val_loss: 0.3710 - val_accuracy: 0.8683\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 7s 111us/sample - loss: 0.3396 - accuracy: 0.8767 - val_loss: 0.3681 - val_accuracy: 0.8682\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3381 - accuracy: 0.8778 - val_loss: 0.3657 - val_accuracy: 0.8696\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3351 - accuracy: 0.8791 - val_loss: 0.3647 - val_accuracy: 0.8693\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3320 - accuracy: 0.8802 - val_loss: 0.3654 - val_accuracy: 0.8682\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3279 - accuracy: 0.8821 - val_loss: 0.3609 - val_accuracy: 0.8690\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.3255 - accuracy: 0.8821 - val_loss: 0.3594 - val_accuracy: 0.8704\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.3213 - accuracy: 0.8838 - val_loss: 0.3568 - val_accuracy: 0.8735\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.3199 - accuracy: 0.8845 - val_loss: 0.3554 - val_accuracy: 0.8713\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3181 - accuracy: 0.8857 - val_loss: 0.3548 - val_accuracy: 0.8732\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3152 - accuracy: 0.8863 - val_loss: 0.3522 - val_accuracy: 0.8727\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3117 - accuracy: 0.8864 - val_loss: 0.3493 - val_accuracy: 0.8742\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3101 - accuracy: 0.8863 - val_loss: 0.3491 - val_accuracy: 0.8735\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3056 - accuracy: 0.8892 - val_loss: 0.3480 - val_accuracy: 0.8751\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3059 - accuracy: 0.8889 - val_loss: 0.3470 - val_accuracy: 0.8754\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3017 - accuracy: 0.8893 - val_loss: 0.3462 - val_accuracy: 0.8750\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3002 - accuracy: 0.8905 - val_loss: 0.3439 - val_accuracy: 0.8769\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2972 - accuracy: 0.8921 - val_loss: 0.3435 - val_accuracy: 0.8760\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2948 - accuracy: 0.8923 - val_loss: 0.3414 - val_accuracy: 0.8771\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2936 - accuracy: 0.8938 - val_loss: 0.3411 - val_accuracy: 0.8755\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2918 - accuracy: 0.8942 - val_loss: 0.3397 - val_accuracy: 0.8776\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2890 - accuracy: 0.8950 - val_loss: 0.3391 - val_accuracy: 0.8779\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2860 - accuracy: 0.8967 - val_loss: 0.3399 - val_accuracy: 0.8773\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2838 - accuracy: 0.8966 - val_loss: 0.3370 - val_accuracy: 0.8766\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2811 - accuracy: 0.8969 - val_loss: 0.3349 - val_accuracy: 0.8781\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2806 - accuracy: 0.8979 - val_loss: 0.3352 - val_accuracy: 0.8781\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2784 - accuracy: 0.8974 - val_loss: 0.3332 - val_accuracy: 0.8794\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2768 - accuracy: 0.8992 - val_loss: 0.3342 - val_accuracy: 0.8783\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.2735 - accuracy: 0.9004 - val_loss: 0.3324 - val_accuracy: 0.8792\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2716 - accuracy: 0.9003 - val_loss: 0.3379 - val_accuracy: 0.8775\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2711 - accuracy: 0.9022 - val_loss: 0.3303 - val_accuracy: 0.8799\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2696 - accuracy: 0.9021 - val_loss: 0.3302 - val_accuracy: 0.8786\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2679 - accuracy: 0.9024 - val_loss: 0.3299 - val_accuracy: 0.8792\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2644 - accuracy: 0.9042 - val_loss: 0.3293 - val_accuracy: 0.8810\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2638 - accuracy: 0.9044 - val_loss: 0.3277 - val_accuracy: 0.8814\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2607 - accuracy: 0.9046 - val_loss: 0.3290 - val_accuracy: 0.8789\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2605 - accuracy: 0.9057 - val_loss: 0.3279 - val_accuracy: 0.8798\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2573 - accuracy: 0.9067 - val_loss: 0.3273 - val_accuracy: 0.8813\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2551 - accuracy: 0.9072 - val_loss: 0.3282 - val_accuracy: 0.8809\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2543 - accuracy: 0.9076 - val_loss: 0.3248 - val_accuracy: 0.8811\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2518 - accuracy: 0.9084 - val_loss: 0.3260 - val_accuracy: 0.8817\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2506 - accuracy: 0.9094 - val_loss: 0.3273 - val_accuracy: 0.8811\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2493 - accuracy: 0.9088 - val_loss: 0.3238 - val_accuracy: 0.8821\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2453 - accuracy: 0.9104 - val_loss: 0.3253 - val_accuracy: 0.8821\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2443 - accuracy: 0.9115 - val_loss: 0.3267 - val_accuracy: 0.8802\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2429 - accuracy: 0.9114 - val_loss: 0.3257 - val_accuracy: 0.8825\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2414 - accuracy: 0.9124 - val_loss: 0.3223 - val_accuracy: 0.8816\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2395 - accuracy: 0.9127 - val_loss: 0.3239 - val_accuracy: 0.8814\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2378 - accuracy: 0.9138 - val_loss: 0.3232 - val_accuracy: 0.8830\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.2360 - accuracy: 0.9155 - val_loss: 0.3231 - val_accuracy: 0.8819\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2354 - accuracy: 0.9154 - val_loss: 0.3223 - val_accuracy: 0.8815\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2337 - accuracy: 0.9156 - val_loss: 0.3232 - val_accuracy: 0.8816\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2315 - accuracy: 0.9162 - val_loss: 0.3207 - val_accuracy: 0.8818\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2313 - accuracy: 0.9165 - val_loss: 0.3216 - val_accuracy: 0.8818\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2270 - accuracy: 0.9171 - val_loss: 0.3238 - val_accuracy: 0.8829\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2267 - accuracy: 0.9194 - val_loss: 0.3219 - val_accuracy: 0.8824\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2254 - accuracy: 0.9181 - val_loss: 0.3218 - val_accuracy: 0.8828\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2232 - accuracy: 0.9189 - val_loss: 0.3212 - val_accuracy: 0.8806\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2214 - accuracy: 0.9200 - val_loss: 0.3251 - val_accuracy: 0.8818\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2207 - accuracy: 0.9205 - val_loss: 0.3220 - val_accuracy: 0.8824\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2193 - accuracy: 0.9207 - val_loss: 0.3219 - val_accuracy: 0.8828\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2170 - accuracy: 0.9218 - val_loss: 0.3229 - val_accuracy: 0.8844\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2171 - accuracy: 0.9215 - val_loss: 0.3240 - val_accuracy: 0.8825\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2133 - accuracy: 0.9224 - val_loss: 0.3216 - val_accuracy: 0.8825\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2151 - accuracy: 0.9222 - val_loss: 0.3224 - val_accuracy: 0.8822\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2108 - accuracy: 0.9239 - val_loss: 0.3211 - val_accuracy: 0.8824\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2106 - accuracy: 0.9239 - val_loss: 0.3242 - val_accuracy: 0.8826\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2093 - accuracy: 0.9245 - val_loss: 0.3240 - val_accuracy: 0.8834\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2072 - accuracy: 0.9256 - val_loss: 0.3226 - val_accuracy: 0.8833\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2069 - accuracy: 0.9246 - val_loss: 0.3215 - val_accuracy: 0.8839\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2058 - accuracy: 0.9258 - val_loss: 0.3236 - val_accuracy: 0.8832\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2032 - accuracy: 0.9270 - val_loss: 0.3223 - val_accuracy: 0.8850\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2031 - accuracy: 0.9272 - val_loss: 0.3269 - val_accuracy: 0.8816\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2001 - accuracy: 0.9285 - val_loss: 0.3254 - val_accuracy: 0.8835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff98100a990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-O-fFxnOIVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiP7IL52OIVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr2YsZV0OIV0",
        "colab_type": "text"
      },
      "source": [
        "## Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ojW6-oOIV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "83767d65-0618-4bef-b2cc-15176976dcde"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch multiple                  3136      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  78500     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              multiple                  10100     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              multiple                  1010      \n",
            "=================================================================\n",
            "Total params: 92,746\n",
            "Trainable params: 91,178\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFGmbZLOIV5",
        "colab_type": "text"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIkbMEN5OIV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model has been compiled and run in above step.\n",
        "# Model performs better when learning rate hyper parameter is introduced and tuned\n",
        "# model performs better with addition of layers and thus increase in accuracy\n",
        "# Final Test accuracy in the model is 86.96% which is better than the intial test accuracy. "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}