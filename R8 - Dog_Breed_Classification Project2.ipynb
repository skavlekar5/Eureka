{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Project2_Dog_Breed_Classification_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kIWaR5ZpKlJ"
      },
      "source": [
        "## Dog Breed Classification\n",
        "\n",
        "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F7MDmaAw2xGO"
      },
      "source": [
        "### Load Dataset Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BZWpQv1OwqYK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "531d4894-2568-4f63-e9be-6edf417357b7"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tf78x2lYx1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea70913b-97e0-4fe6-d06d-dbe575bf818e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fVhB9OopxFbX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d09d879c-ac28-4a95-e761-ed5252de5300"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "import cv2\n",
        "import scipy.misc\n",
        "from skimage import transform\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from skimage.transform import resize\n",
        "from keras.models import Model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1q2zzIaUprk_"
      },
      "source": [
        "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tp6FvAToxUFs",
        "colab": {}
      },
      "source": [
        "project_path = \"drive/My Drive/Dog_breed/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rydR_j8lqUei"
      },
      "source": [
        "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3350WZM4w4EL",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'train.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NHq1iBCfFjE",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for test.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_fxzynvB2YCb",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'test.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnUMhQrDfJmz",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for sample_submission.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4PyTxE8q2jLf",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'sample_submission.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G9RIxB-fOLT",
        "colab_type": "text"
      },
      "source": [
        "Repeat the same step for labels.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rXtnEoEixbgi",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(project_path+'labels.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJc1lVrW_jmL",
        "colab_type": "text"
      },
      "source": [
        "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aYmJKmDqqpng"
      },
      "source": [
        "### Read labels.csv file using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmlJ2VMY96IZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "3c727a3f-3dfe-4dbd-b663-c943527c2102"
      },
      "source": [
        "labels = pd.read_csv('labels.csv')\n",
        "labels.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id             breed\n",
              "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
              "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
              "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
              "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QP8YAzQvqyK-"
      },
      "source": [
        "### Print the count of each category of Dogs given in the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L2naXlr96Im",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "6f9f6a6e-fb8c-4ceb-8bc1-5e272ca9ff0f"
      },
      "source": [
        "labels.breed.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scottish_deerhound      126\n",
              "maltese_dog             117\n",
              "afghan_hound            116\n",
              "entlebucher             115\n",
              "bernese_mountain_dog    114\n",
              "                       ... \n",
              "golden_retriever         67\n",
              "brabancon_griffon        67\n",
              "komondor                 67\n",
              "eskimo_dog               66\n",
              "briard                   66\n",
              "Name: breed, Length: 120, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLm3W5RN96Ir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "817aa8db-73c4-4a01-da7c-d8f72a24aca9"
      },
      "source": [
        "#top 20 breed and their count\n",
        "top_breeds = sorted(list(labels['breed'].value_counts().head(20).index))\n",
        "labelstop = labels[labels['breed'].isin(top_breeds)]\n",
        "labelstop.breed.value_counts().plot(kind='bar')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f19c87545c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFjCAYAAADGh0tzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhZ9k3iucS5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "806b0276-3e38-4464-dee3-42cbf1202abe"
      },
      "source": [
        "print(\"Dog- Unique Classes\",labels[\"breed\"].unique())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dog- Unique Classes ['boston_bull' 'dingo' 'pekinese' 'bluetick' 'golden_retriever'\n",
            " 'bedlington_terrier' 'borzoi' 'basenji' 'scottish_deerhound'\n",
            " 'shetland_sheepdog' 'walker_hound' 'maltese_dog' 'norfolk_terrier'\n",
            " 'african_hunting_dog' 'wire-haired_fox_terrier' 'redbone'\n",
            " 'lakeland_terrier' 'boxer' 'doberman' 'otterhound' 'standard_schnauzer'\n",
            " 'irish_water_spaniel' 'black-and-tan_coonhound' 'cairn' 'affenpinscher'\n",
            " 'labrador_retriever' 'ibizan_hound' 'english_setter' 'weimaraner'\n",
            " 'giant_schnauzer' 'groenendael' 'dhole' 'toy_poodle' 'border_terrier'\n",
            " 'tibetan_terrier' 'norwegian_elkhound' 'shih-tzu' 'irish_terrier'\n",
            " 'kuvasz' 'german_shepherd' 'greater_swiss_mountain_dog' 'basset'\n",
            " 'australian_terrier' 'schipperke' 'rhodesian_ridgeback' 'irish_setter'\n",
            " 'appenzeller' 'bloodhound' 'samoyed' 'miniature_schnauzer'\n",
            " 'brittany_spaniel' 'kelpie' 'papillon' 'border_collie' 'entlebucher'\n",
            " 'collie' 'malamute' 'welsh_springer_spaniel' 'chihuahua' 'saluki' 'pug'\n",
            " 'malinois' 'komondor' 'airedale' 'leonberg' 'mexican_hairless'\n",
            " 'bull_mastiff' 'bernese_mountain_dog' 'american_staffordshire_terrier'\n",
            " 'lhasa' 'cardigan' 'italian_greyhound' 'clumber' 'scotch_terrier'\n",
            " 'afghan_hound' 'old_english_sheepdog' 'saint_bernard'\n",
            " 'miniature_pinscher' 'eskimo_dog' 'irish_wolfhound' 'brabancon_griffon'\n",
            " 'toy_terrier' 'chow' 'flat-coated_retriever' 'norwich_terrier'\n",
            " 'soft-coated_wheaten_terrier' 'staffordshire_bullterrier'\n",
            " 'english_foxhound' 'gordon_setter' 'siberian_husky' 'newfoundland'\n",
            " 'briard' 'chesapeake_bay_retriever' 'dandie_dinmont' 'great_pyrenees'\n",
            " 'beagle' 'vizsla' 'west_highland_white_terrier' 'kerry_blue_terrier'\n",
            " 'whippet' 'sealyham_terrier' 'standard_poodle' 'keeshond'\n",
            " 'japanese_spaniel' 'miniature_poodle' 'pomeranian'\n",
            " 'curly-coated_retriever' 'yorkshire_terrier' 'pembroke' 'great_dane'\n",
            " 'blenheim_spaniel' 'silky_terrier' 'sussex_spaniel'\n",
            " 'german_short-haired_pointer' 'french_bulldog' 'bouvier_des_flandres'\n",
            " 'tibetan_mastiff' 'english_springer' 'cocker_spaniel' 'rottweiler']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFZmfL1ackFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0b2d44c-7244-4469-ef99-96915e17675c"
      },
      "source": [
        "print(\"Total number of dog breeds = \",labels.breed.nunique())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of dog breeds =  120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WI94_Qcc0D4M"
      },
      "source": [
        "### Get one-hot encodings of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q48iAcY196I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nlWmRNM96I8",
        "colab_type": "code",
        "outputId": "bf41a7ea-5b69-4119-fe09-69da16d951ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "transfomed_label = encoder.fit_transform(labels.breed)\n",
        "print(transfomed_label)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWaJ9naXfoiU",
        "colab_type": "text"
      },
      "source": [
        "## Preparing training dataset\n",
        "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
        "2. Create 2 variables <br> \n",
        "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
        "     b.  y_train - Corresponding label of the dog <br>\n",
        "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
        "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aC2f9ecR0XGR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0296c36-b9ca-4209-da64-dd5780af6cc9"
      },
      "source": [
        "img_rows = 128\n",
        "img_cols = 128\n",
        "x_train = []\n",
        "y_train = []\n",
        "i = 0 \n",
        "\n",
        "for f, breed in tqdm(labels.values):\n",
        "    img = cv2.imread('./train/{}.jpg'.format(f))\n",
        "    label = transfomed_label[i]\n",
        "    x_train.append(cv2.resize(img, (img_rows, img_cols)))\n",
        "    y_train.append(label)\n",
        "    i += 1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10222/10222 [00:32<00:00, 316.41it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nkkZEpOe0ipk",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fgJ6x2CbntI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle_out = open(\"drive/My Drive/Dog_breed/x_train.pickle\",\"wb\")\n",
        "pickle.dump(x_train,pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"drive/My Drive/Dog_breed/y_train.pickle\",\"wb\")\n",
        "pickle.dump(y_train,pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ega0AJmbn0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle_in = open(\"drive/My Drive/Dog_breed/x_train.pickle\",\"rb\")\n",
        "x_train = pickle.load(pickle_in) \n",
        "pickle_in.close()\n",
        "\n",
        "pickle_in = open(\"drive/My Drive/Dog_breed/y_train.pickle\",\"rb\")\n",
        "y_train = pickle.load(pickle_in) \n",
        "pickle_in.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ioWDEgElBOs",
        "colab_type": "text"
      },
      "source": [
        "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ARn76j3U1CDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "052d86be-6cb5-45c7-dd25-5634cad2c950"
      },
      "source": [
        "y_train_norm= np.array(y_train, np.uint8)\n",
        "x_train_norm = np.array(x_train, np.float32) / 255.\n",
        "\n",
        "print(y_train_norm.shape)\n",
        "print(x_train_norm.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10222, 120)\n",
            "(10222, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bdCXuAE11gZL"
      },
      "source": [
        "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpWx-pgV96Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1_train,X1_test,y1_train,y1_test = train_test_split(x_train_norm, y_train_norm, test_size=0.3, random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XkL-N1jDsU8m"
      },
      "source": [
        "### Loading the test data\n",
        "Read the id column from the samples_submission.csv and store it in test_img"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DnpXdpd9b3E7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "762b48e7-5d4c-4946-c90f-f7d0266d209e"
      },
      "source": [
        "test_data= pd.read_csv('sample_submission.csv')\n",
        "test_data.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>affenpinscher</th>\n",
              "      <th>afghan_hound</th>\n",
              "      <th>african_hunting_dog</th>\n",
              "      <th>airedale</th>\n",
              "      <th>american_staffordshire_terrier</th>\n",
              "      <th>appenzeller</th>\n",
              "      <th>australian_terrier</th>\n",
              "      <th>basenji</th>\n",
              "      <th>basset</th>\n",
              "      <th>beagle</th>\n",
              "      <th>bedlington_terrier</th>\n",
              "      <th>bernese_mountain_dog</th>\n",
              "      <th>black-and-tan_coonhound</th>\n",
              "      <th>blenheim_spaniel</th>\n",
              "      <th>bloodhound</th>\n",
              "      <th>bluetick</th>\n",
              "      <th>border_collie</th>\n",
              "      <th>border_terrier</th>\n",
              "      <th>borzoi</th>\n",
              "      <th>boston_bull</th>\n",
              "      <th>bouvier_des_flandres</th>\n",
              "      <th>boxer</th>\n",
              "      <th>brabancon_griffon</th>\n",
              "      <th>briard</th>\n",
              "      <th>brittany_spaniel</th>\n",
              "      <th>bull_mastiff</th>\n",
              "      <th>cairn</th>\n",
              "      <th>cardigan</th>\n",
              "      <th>chesapeake_bay_retriever</th>\n",
              "      <th>chihuahua</th>\n",
              "      <th>chow</th>\n",
              "      <th>clumber</th>\n",
              "      <th>cocker_spaniel</th>\n",
              "      <th>collie</th>\n",
              "      <th>curly-coated_retriever</th>\n",
              "      <th>dandie_dinmont</th>\n",
              "      <th>dhole</th>\n",
              "      <th>dingo</th>\n",
              "      <th>doberman</th>\n",
              "      <th>...</th>\n",
              "      <th>norwegian_elkhound</th>\n",
              "      <th>norwich_terrier</th>\n",
              "      <th>old_english_sheepdog</th>\n",
              "      <th>otterhound</th>\n",
              "      <th>papillon</th>\n",
              "      <th>pekinese</th>\n",
              "      <th>pembroke</th>\n",
              "      <th>pomeranian</th>\n",
              "      <th>pug</th>\n",
              "      <th>redbone</th>\n",
              "      <th>rhodesian_ridgeback</th>\n",
              "      <th>rottweiler</th>\n",
              "      <th>saint_bernard</th>\n",
              "      <th>saluki</th>\n",
              "      <th>samoyed</th>\n",
              "      <th>schipperke</th>\n",
              "      <th>scotch_terrier</th>\n",
              "      <th>scottish_deerhound</th>\n",
              "      <th>sealyham_terrier</th>\n",
              "      <th>shetland_sheepdog</th>\n",
              "      <th>shih-tzu</th>\n",
              "      <th>siberian_husky</th>\n",
              "      <th>silky_terrier</th>\n",
              "      <th>soft-coated_wheaten_terrier</th>\n",
              "      <th>staffordshire_bullterrier</th>\n",
              "      <th>standard_poodle</th>\n",
              "      <th>standard_schnauzer</th>\n",
              "      <th>sussex_spaniel</th>\n",
              "      <th>tibetan_mastiff</th>\n",
              "      <th>tibetan_terrier</th>\n",
              "      <th>toy_poodle</th>\n",
              "      <th>toy_terrier</th>\n",
              "      <th>vizsla</th>\n",
              "      <th>walker_hound</th>\n",
              "      <th>weimaraner</th>\n",
              "      <th>welsh_springer_spaniel</th>\n",
              "      <th>west_highland_white_terrier</th>\n",
              "      <th>whippet</th>\n",
              "      <th>wire-haired_fox_terrier</th>\n",
              "      <th>yorkshire_terrier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.008333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id  ...  yorkshire_terrier\n",
              "0  000621fb3cbb32d8935728e48679680e  ...           0.008333\n",
              "1  00102ee9d8eb90812350685311fe5890  ...           0.008333\n",
              "2  0012a730dfa437f5f3613fb75efcd4ce  ...           0.008333\n",
              "3  001510bc8570bbeee98c8d80c8a95ec1  ...           0.008333\n",
              "4  001a5f3114548acdefa3d4da05474c2e  ...           0.008333\n",
              "\n",
              "[5 rows x 121 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk3ew4Lse9EF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "c6c57814-9cc7-4541-bf0c-c661ba28698a"
      },
      "source": [
        "test_img = test_data['id']\n",
        "test_img"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        000621fb3cbb32d8935728e48679680e\n",
              "1        00102ee9d8eb90812350685311fe5890\n",
              "2        0012a730dfa437f5f3613fb75efcd4ce\n",
              "3        001510bc8570bbeee98c8d80c8a95ec1\n",
              "4        001a5f3114548acdefa3d4da05474c2e\n",
              "                       ...               \n",
              "10352    ffeda8623d4eee33c6d1156a2ecbfcf8\n",
              "10353    fff1ec9e6e413275984966f745a313b0\n",
              "10354    fff74b59b758bbbf13a5793182a9bbe4\n",
              "10355    fff7d50d848e8014ac1e9172dc6762a3\n",
              "10356    fffbff22c1f51e3dc80c4bf04089545b\n",
              "Name: id, Length: 10357, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEJqZIMbm0Jo",
        "colab_type": "text"
      },
      "source": [
        "Run the below code to load the test image files in x_test_feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zf7n4WG-b3Hv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ceb5b0f-b238-417c-b294-a0038626feb1"
      },
      "source": [
        "x_test_feature = []\n",
        "i = 0 # initialisation\n",
        "for f in tqdm(test_img.values): # f for format ,jpg\n",
        "    img = cv2.imread('./test/{}.jpg'.format(f), 0)\n",
        "    img_resize = cv2.resize(img, (img_rows, img_cols)) \n",
        "    x_test_feature.append(img_resize)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10357/10357 [00:15<00:00, 668.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9My6qSyDnE-_",
        "colab_type": "text"
      },
      "source": [
        "Normalize the test data and convert it into 4 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93n-IntMnJGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "707d96b9-5fe6-478f-e2e3-e9aafecaec0d"
      },
      "source": [
        "x_test_feature = np.array(x_test_feature, np.float32) / 255.\n",
        "x_test_feature.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10357, 128, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zKezNJVMsocP"
      },
      "source": [
        "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
        "\n",
        "1. Add a Dense layer with 256 neurons with `relu` activation\n",
        "\n",
        "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2jxTY2S96J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_BAvCzo96J6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5),strides =(1,1),activation='relu',input_shape=(128,128,3)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3),strides =(1,1),activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides =(2,2), padding='valid'))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "#model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),strides =(2,2),activation='relu'))\n",
        "#model.add(tf.keras.layers.BatchNormalization())\n",
        "#model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),strides =(2,2),activation='relu'))\n",
        "#model.add(tf.keras.layers.BatchNormalization())\n",
        "#model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2),strides =(2,2), padding='valid'))\n",
        "#model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Flatten()) ## Deep neural network\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "#model.add(tf.keras.layers.LayerNormalization())\n",
        "#model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "#model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Dense(120, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR7WwoF3CAog",
        "colab_type": "code",
        "outputId": "818286a9-0663-4f38-8eb0-d0e869a78f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 124, 124, 32)      2432      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 124, 124, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 122, 122, 32)      9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 122, 122, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 119072)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               30482688  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 30,525,464\n",
            "Trainable params: 30,525,336\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8EXw6_oqpR",
        "colab_type": "text"
      },
      "source": [
        "### Use batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IriIc37NozbK",
        "colab_type": "code",
        "outputId": "8f0fcbb2-55e0-4531-c317-e8dcaefa1e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "model.fit(X1_train,y1_train,batch_size=128,epochs=10,validation_data=(X1_test,y1_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7155 samples, validate on 3067 samples\n",
            "Epoch 1/10\n",
            "7155/7155 [==============================] - 70s 10ms/sample - loss: 6.8145 - accuracy: 0.0092 - val_loss: 12.4635 - val_accuracy: 0.0082\n",
            "Epoch 2/10\n",
            "7155/7155 [==============================] - 69s 10ms/sample - loss: 4.8095 - accuracy: 0.0129 - val_loss: 44.2933 - val_accuracy: 0.0068\n",
            "Epoch 3/10\n",
            "7155/7155 [==============================] - 71s 10ms/sample - loss: 4.8103 - accuracy: 0.0145 - val_loss: 64.3714 - val_accuracy: 0.0098\n",
            "Epoch 4/10\n",
            "7155/7155 [==============================] - 70s 10ms/sample - loss: 4.7949 - accuracy: 0.0165 - val_loss: 22.7080 - val_accuracy: 0.0153\n",
            "Epoch 5/10\n",
            "7155/7155 [==============================] - 70s 10ms/sample - loss: 4.7489 - accuracy: 0.0214 - val_loss: 120.2594 - val_accuracy: 0.0124\n",
            "Epoch 6/10\n",
            "7155/7155 [==============================] - 71s 10ms/sample - loss: 4.7147 - accuracy: 0.0236 - val_loss: 82.9038 - val_accuracy: 0.0121\n",
            "Epoch 7/10\n",
            "7155/7155 [==============================] - 71s 10ms/sample - loss: 4.6725 - accuracy: 0.0295 - val_loss: 58.2539 - val_accuracy: 0.0157\n",
            "Epoch 8/10\n",
            "7155/7155 [==============================] - 71s 10ms/sample - loss: 4.6386 - accuracy: 0.0342 - val_loss: 40.2851 - val_accuracy: 0.0189\n",
            "Epoch 9/10\n",
            "7155/7155 [==============================] - 70s 10ms/sample - loss: 4.6005 - accuracy: 0.0387 - val_loss: 20.8882 - val_accuracy: 0.0163\n",
            "Epoch 10/10\n",
            "7155/7155 [==============================] - 69s 10ms/sample - loss: 4.5662 - accuracy: 0.0421 - val_loss: 6.6720 - val_accuracy: 0.0163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19c8845a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PR9j5_Xozmd",
        "colab_type": "code",
        "outputId": "43ee74e4-3193-4545-af97-e38971401e5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores = model.evaluate(X1_train, y1_train, verbose=0)\n",
        "print(\"Train Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 3.56%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLSGWTWwEmXj",
        "colab_type": "code",
        "outputId": "1053257d-e070-466b-de6b-56141f149469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores = model.evaluate(X1_test, y1_test, verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 1.63%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8hWaKmjoz69",
        "colab_type": "text"
      },
      "source": [
        "#The model accuracy is very poor !!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "agJKkc6xtKiq"
      },
      "source": [
        "### Use Data Augmentation in the above model to see if the accuracy improves\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "31Mn8qnZb3Ru",
        "colab": {}
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=300, # Degree range for random rotations\n",
        "                            width_shift_range=0.5, # Range for random horizontal shifts\n",
        "                            height_shift_range=0.5, # Range for random vertical shifts\n",
        "                            zoom_range=0.5, # Range for random zoom\n",
        "                            horizontal_flip=True, # Randomly flip inputs horizontally\n",
        "                            vertical_flip=True) # Randomly flip inputs vertically"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sssbaTfxlkk"
      },
      "source": [
        "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
        "\n",
        "You need to use train_datagen.flow() and val_datagen.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sehaRgT-96KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = datagen.flow(X1_train, y1_train)\n",
        "val_generator = datagen.flow(X1_test, y1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVFQJZw3x4-C"
      },
      "source": [
        "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J1K2MqHbuPUa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "3f26ef85-0148-42bf-f052-b480f5f4e6eb"
      },
      "source": [
        "model.fit_generator(train_generator,\n",
        "                   steps_per_epoch=X1_train.shape[0] // 128,\n",
        "                   epochs=10,\n",
        "                   verbose=2,\n",
        "                   validation_data=val_generator)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-34-edc74f969ba7>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 55 steps, validate for 96 steps\n",
            "Epoch 1/10\n",
            "55/55 - 34s - loss: 9.9836 - accuracy: 0.0136 - val_loss: 6.4864 - val_accuracy: 0.0082\n",
            "Epoch 2/10\n",
            "55/55 - 34s - loss: 4.8604 - accuracy: 0.0108 - val_loss: 4.7856 - val_accuracy: 0.0085\n",
            "Epoch 3/10\n",
            "55/55 - 34s - loss: 4.7930 - accuracy: 0.0142 - val_loss: 4.7854 - val_accuracy: 0.0085\n",
            "Epoch 4/10\n",
            "55/55 - 34s - loss: 4.8052 - accuracy: 0.0114 - val_loss: 4.7853 - val_accuracy: 0.0085\n",
            "Epoch 5/10\n",
            "55/55 - 35s - loss: 4.7915 - accuracy: 0.0108 - val_loss: 4.8001 - val_accuracy: 0.0085\n",
            "Epoch 6/10\n",
            "55/55 - 34s - loss: 4.7896 - accuracy: 0.0102 - val_loss: 4.7849 - val_accuracy: 0.0085\n",
            "Epoch 7/10\n",
            "55/55 - 35s - loss: 4.7754 - accuracy: 0.0103 - val_loss: 4.7852 - val_accuracy: 0.0085\n",
            "Epoch 8/10\n",
            "55/55 - 34s - loss: 4.7786 - accuracy: 0.0155 - val_loss: 4.7850 - val_accuracy: 0.0085\n",
            "Epoch 9/10\n",
            "55/55 - 34s - loss: 4.7805 - accuracy: 0.0097 - val_loss: 4.7863 - val_accuracy: 0.0085\n",
            "Epoch 10/10\n",
            "55/55 - 34s - loss: 4.7739 - accuracy: 0.0114 - val_loss: 4.7849 - val_accuracy: 0.0085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f19879ac2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is76fkC8g69M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40c65f5b-c978-49d8-eff3-a0649c8cab85"
      },
      "source": [
        "scores = model.evaluate(X1_train, y1_train, verbose=0)\n",
        "print(\"Train Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 1.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi7Vzi2vg3km",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b548edae-9ebf-440d-ea72-38a9ded4700c"
      },
      "source": [
        "scores = model.evaluate(X1_test, y1_test, verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2zmLztqo5DY",
        "colab_type": "text"
      },
      "source": [
        "# Model accuracy is still poor!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSTATrhsAo7L",
        "colab_type": "text"
      },
      "source": [
        "### Lets use Transfer Learning\n",
        "\n",
        "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy5JdbW6pIvD",
        "colab_type": "text"
      },
      "source": [
        "Use the below code to load VGG16 weights trained on ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrqs0zg7ApNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "# Instantiate the model with the pre-trained weights (no top)\n",
        "base_model= VGG16(weights=('drive/My Drive/Dog_breed/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
        "                 input_shape=(128,128,3),include_top=False,pooling='avg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EItOlRBGpV_A",
        "colab_type": "text"
      },
      "source": [
        "Print the summary of the base_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQsEBgnlpHjH",
        "colab_type": "code",
        "outputId": "507f2750-dd17-4d6d-f5c1-81bbb2370186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        }
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHpeOyW0qauW",
        "colab_type": "text"
      },
      "source": [
        "### Add the following classification layers to the imported VGG Model <br>\n",
        "1. Flatten Layer\n",
        "2. Dense layer with 1024 neurons with activation as Relu\n",
        "3. Dense layer with 256 neurons with activation as Relu\n",
        "4. Dense layer with 120 neurons with activation as Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BpT4MLkqoaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fl1=tf.keras.layers.Flatten(name='flatten')\n",
        "dl1=tf.keras.layers.Dense(1024, activation='relu',name='dense1')\n",
        "dl2=tf.keras.layers.Dense(512, activation='relu',name='dense2')\n",
        "dp=tf.keras.layers.Dropout(0.2,name='drop')\n",
        "dout=tf.keras.layers.Dense(120, activation='softmax',name='out')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeQem0pHITIj",
        "colab_type": "text"
      },
      "source": [
        "### Make all the layers in the base_model (VGG16) to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7w9CSPvIRnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "2763e654-5e3d-4306-be47-dad6b446c9bb"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "base_model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWNnTQwCkatS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg = tf.keras.models.Sequential([\n",
        "  base_model,\n",
        "  fl1,\n",
        "  dl1,\n",
        "  dl2,\n",
        "  dp,\n",
        "  dout\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj-BwqgfIkdv",
        "colab_type": "text"
      },
      "source": [
        "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD5fAgVQIpKZ",
        "colab_type": "text"
      },
      "source": [
        "Try to get training and validation accuracy to be more than 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJgx5kOCRfri",
        "colab_type": "code",
        "outputId": "215bae11-3e6f-4b03-b2f7-cbb867f744a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model_vgg.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model_vgg.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "drop (Dropout)               (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "out (Dense)                  (None, 120)               61560     \n",
            "=================================================================\n",
            "Total params: 15,826,360\n",
            "Trainable params: 1,111,672\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9_QVMnHi11r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa9de2e4-7ff5-4681-ca96-165039025877"
      },
      "source": [
        "model_vgg.fit_generator(train_generator,steps_per_epoch=100,epochs=50,validation_data=val_generator, validation_steps=50, verbose=1) "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 100 steps, validate for 50 steps\n",
            "Epoch 1/50\n",
            "100/100 [==============================] - 57s 571ms/step - loss: 4.8173 - accuracy: 0.0084 - val_loss: 4.7886 - val_accuracy: 0.0075\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 56s 558ms/step - loss: 4.7867 - accuracy: 0.0110 - val_loss: 4.7862 - val_accuracy: 0.0069\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 56s 558ms/step - loss: 4.7696 - accuracy: 0.0185 - val_loss: 4.7723 - val_accuracy: 0.0113\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 56s 561ms/step - loss: 4.7248 - accuracy: 0.0191 - val_loss: 4.7395 - val_accuracy: 0.0200\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 55s 552ms/step - loss: 4.6696 - accuracy: 0.0250 - val_loss: 4.6929 - val_accuracy: 0.0213\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 57s 568ms/step - loss: 4.6190 - accuracy: 0.0341 - val_loss: 4.6411 - val_accuracy: 0.0269\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 56s 563ms/step - loss: 4.5932 - accuracy: 0.0300 - val_loss: 4.5876 - val_accuracy: 0.0275\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 57s 567ms/step - loss: 4.5320 - accuracy: 0.0338 - val_loss: 4.5111 - val_accuracy: 0.0500\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 56s 563ms/step - loss: 4.4936 - accuracy: 0.0378 - val_loss: 4.5149 - val_accuracy: 0.0394\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 56s 562ms/step - loss: 4.4428 - accuracy: 0.0386 - val_loss: 4.4513 - val_accuracy: 0.0444\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 56s 562ms/step - loss: 4.4016 - accuracy: 0.0455 - val_loss: 4.4648 - val_accuracy: 0.0356\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 57s 572ms/step - loss: 4.3633 - accuracy: 0.0468 - val_loss: 4.4119 - val_accuracy: 0.0444\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 56s 560ms/step - loss: 4.3667 - accuracy: 0.0487 - val_loss: 4.4060 - val_accuracy: 0.0519\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 56s 562ms/step - loss: 4.3017 - accuracy: 0.0587 - val_loss: 4.3097 - val_accuracy: 0.0531\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 56s 561ms/step - loss: 4.3074 - accuracy: 0.0640 - val_loss: 4.4059 - val_accuracy: 0.0444\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 56s 564ms/step - loss: 4.2452 - accuracy: 0.0647 - val_loss: 4.3166 - val_accuracy: 0.0587\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 56s 564ms/step - loss: 4.2341 - accuracy: 0.0684 - val_loss: 4.2907 - val_accuracy: 0.0675\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 56s 557ms/step - loss: 4.2078 - accuracy: 0.0675 - val_loss: 4.3670 - val_accuracy: 0.0581\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 55s 552ms/step - loss: 4.2046 - accuracy: 0.0637 - val_loss: 4.3440 - val_accuracy: 0.0619\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 4.2129 - accuracy: 0.0659 - val_loss: 4.3204 - val_accuracy: 0.0581\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 56s 561ms/step - loss: 4.1751 - accuracy: 0.0750 - val_loss: 4.3108 - val_accuracy: 0.0650\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 56s 558ms/step - loss: 4.1763 - accuracy: 0.0675 - val_loss: 4.2579 - val_accuracy: 0.0650\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 57s 574ms/step - loss: 4.1514 - accuracy: 0.0722 - val_loss: 4.3292 - val_accuracy: 0.0644\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 56s 560ms/step - loss: 4.1493 - accuracy: 0.0766 - val_loss: 4.2804 - val_accuracy: 0.0675\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 56s 560ms/step - loss: 4.1443 - accuracy: 0.0806 - val_loss: 4.2469 - val_accuracy: 0.0719\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 57s 574ms/step - loss: 4.1268 - accuracy: 0.0794 - val_loss: 4.2534 - val_accuracy: 0.0700\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 56s 561ms/step - loss: 4.1380 - accuracy: 0.0816 - val_loss: 4.2603 - val_accuracy: 0.0669\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 56s 558ms/step - loss: 4.1415 - accuracy: 0.0869 - val_loss: 4.2170 - val_accuracy: 0.0706\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 58s 577ms/step - loss: 4.1576 - accuracy: 0.0835 - val_loss: 4.2514 - val_accuracy: 0.0600\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 60s 598ms/step - loss: 4.0865 - accuracy: 0.0731 - val_loss: 4.2279 - val_accuracy: 0.0719\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 56s 557ms/step - loss: 4.1009 - accuracy: 0.0800 - val_loss: 4.2681 - val_accuracy: 0.0781\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 56s 557ms/step - loss: 4.0964 - accuracy: 0.0778 - val_loss: 4.2086 - val_accuracy: 0.0763\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 55s 552ms/step - loss: 4.0516 - accuracy: 0.0941 - val_loss: 4.2078 - val_accuracy: 0.0781\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 56s 563ms/step - loss: 4.1045 - accuracy: 0.0869 - val_loss: 4.2167 - val_accuracy: 0.0775\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 55s 551ms/step - loss: 4.0882 - accuracy: 0.0803 - val_loss: 4.2174 - val_accuracy: 0.0825\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 56s 556ms/step - loss: 4.0551 - accuracy: 0.0901 - val_loss: 4.2006 - val_accuracy: 0.0731\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 55s 554ms/step - loss: 4.0399 - accuracy: 0.0935 - val_loss: 4.2483 - val_accuracy: 0.0688\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 55s 552ms/step - loss: 4.0528 - accuracy: 0.0894 - val_loss: 4.2020 - val_accuracy: 0.0775\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 4.0542 - accuracy: 0.0878 - val_loss: 4.2268 - val_accuracy: 0.0694\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 57s 570ms/step - loss: 4.0213 - accuracy: 0.0919 - val_loss: 4.1915 - val_accuracy: 0.0763\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 55s 553ms/step - loss: 4.0269 - accuracy: 0.0913 - val_loss: 4.2064 - val_accuracy: 0.0775\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 56s 560ms/step - loss: 4.0097 - accuracy: 0.0973 - val_loss: 4.1780 - val_accuracy: 0.0769\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 56s 557ms/step - loss: 4.0373 - accuracy: 0.0891 - val_loss: 4.1602 - val_accuracy: 0.0800\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 56s 558ms/step - loss: 4.0173 - accuracy: 0.0916 - val_loss: 4.2447 - val_accuracy: 0.0900\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 56s 563ms/step - loss: 3.9944 - accuracy: 0.0891 - val_loss: 4.1843 - val_accuracy: 0.0787\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 4.0159 - accuracy: 0.0925 - val_loss: 4.1971 - val_accuracy: 0.0875\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 56s 560ms/step - loss: 4.0058 - accuracy: 0.0966 - val_loss: 4.1908 - val_accuracy: 0.0737\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 56s 556ms/step - loss: 3.9813 - accuracy: 0.1007 - val_loss: 4.1372 - val_accuracy: 0.0875\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 55s 552ms/step - loss: 3.9981 - accuracy: 0.1001 - val_loss: 4.1858 - val_accuracy: 0.0812\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 56s 557ms/step - loss: 3.9583 - accuracy: 0.1050 - val_loss: 4.1719 - val_accuracy: 0.0862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1986f6ffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUErG1rBogMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "899c653b-7fff-496d-9026-37d195a2ff58"
      },
      "source": [
        "scores = model_vgg.evaluate(X1_train, y1_train, verbose=0)\n",
        "print(\"Train Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 17.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7akkvU0polZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06aff505-711a-482e-b2b6-f4d15dc36191"
      },
      "source": [
        "scores = model_vgg.evaluate(X1_test, y1_test, verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 13.66%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcRqdBQF2JqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## after multiple iterations and tries, not able to bring the model upto expectation. So submitting the assignment with the procedure that has been followed\n",
        "## removed all iterations carried out, to make the notebook readable.\n",
        "## Max accuracy achieved = 27% in train and 18% in validation. which isnt shown in this notebook "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}